{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5ac460",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MaralAminpour/ML-BME-Course-UofA-Fall-2023/blob/main/Week-3-Classification-models/3.2-Classification-models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac043bc5-3dec-4331-961b-4ea610d5c029",
   "metadata": {
    "id": "ac043bc5-3dec-4331-961b-4ea610d5c029"
   },
   "source": [
    "# Binary Classification Models\n",
    "\n",
    "We will go through a series of examples creating different types of binary classification models for the same dataset. Binary classifiers predict two labels. Usually, we'll convert our labels to 0 and 1.  We will use the example of heart disease data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33085db4-86c3-42fa-becc-dd1446cc1832",
   "metadata": {
    "id": "33085db4-86c3-42fa-becc-dd1446cc1832"
   },
   "outputs": [],
   "source": [
    "# Imports needed for this notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Note that if you are using Anaconda, GraphViz won't be installed by default.\n",
    "# You will need to install graphviz and python-graphviz.\n",
    "import graphviz\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report, roc_curve, auc\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4d0d5-4598-4abe-a997-34998afeca25",
   "metadata": {
    "id": "f2f4d0d5-4598-4abe-a997-34998afeca25"
   },
   "source": [
    "First, let's load the data we'll need for all the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbccbe98-7fb2-496d-a4fb-c5d16e81e611",
   "metadata": {
    "id": "cbccbe98-7fb2-496d-a4fb-c5d16e81e611"
   },
   "outputs": [],
   "source": [
    "# This code will download the required data files from GitHub\n",
    "import requests\n",
    "def download_data(source, dest):\n",
    "    base_url = 'https://raw.githubusercontent.com/'\n",
    "    owner = 'SirTurtle'\n",
    "    repo = 'ML-BME-UofA-data'\n",
    "    branch = 'main'\n",
    "    url = '{}/{}/{}/{}/{}'.format(base_url, owner, repo, branch, source)\n",
    "    r = requests.get(url)\n",
    "    f = open(dest, 'wb')\n",
    "    f.write(r.content)\n",
    "    f.close()\n",
    "\n",
    "# Create the temp directory, if it doesn't already exist\n",
    "import os\n",
    "if not os.path.exists('temp'):\n",
    "   os.makedirs('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edc0aa-689f-4f10-8e3d-c8ff3215431d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "80edc0aa-689f-4f10-8e3d-c8ff3215431d",
    "outputId": "3b7f0a67-dba7-4869-8f47-71150b9de9c8"
   },
   "outputs": [],
   "source": [
    "# Download the data\n",
    "download_data('Week-3-Classification-models/data/heart_failure_data.csv', 'temp/heart_failure_data.csv')\n",
    "\n",
    "# Read data file into a dataframe object\n",
    "df = pd.read_csv('temp/heart_failure_data.csv')\n",
    "\n",
    "# Print the first few lines of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a7ab9-d61e-48f9-af6d-c21daae35fef",
   "metadata": {
    "id": "b02a7ab9-d61e-48f9-af6d-c21daae35fef"
   },
   "source": [
    "## Data dictionary\n",
    "\n",
    "**EF**: Ejection Fraction. A measurement of how much blood the left ventricle pumps out with each contraction. Expressed as a percent in the range 0 to 100.\n",
    "\n",
    "**GLS**: Global Longitudinal Strain. A measurement of myocardial deformation along the longitudinal cardiac axis. Expressed as a negative percent in the range 0 to -100.\n",
    "\n",
    "**HF**: Heart Failure class\n",
    "- 0 = Healthy\n",
    "- 1 = Heart failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2478d5-c11e-4275-9eb3-edf85461f8d5",
   "metadata": {
    "id": "6b2478d5-c11e-4275-9eb3-edf85461f8d5"
   },
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Here we use the pandas library in Python to **group a DataFrame by the values** in the 'HF' column and then **count the number of occurrences** of each value in the 'HF' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63acb35f-76be-49a7-84f0-d76fd4956c81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63acb35f-76be-49a7-84f0-d76fd4956c81",
    "outputId": "eeb63543-a7b5-4857-fe1b-18afdea88448"
   },
   "outputs": [],
   "source": [
    "# Check balance of the output variables\n",
    "df.groupby(['HF'])['HF'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5655d2d-5a11-4a41-9035-51d9a9697db8",
   "metadata": {
    "id": "c5655d2d-5a11-4a41-9035-51d9a9697db8"
   },
   "source": [
    "Our example has **an exactly equal number of samples in each class**. If we had an unbalanced dataset, we could balance it by\n",
    "\n",
    "1. **removing some random samples** from the larger class, or by\n",
    "\n",
    "2. **duplicating small samples from the smaller class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf32438-f70e-4e27-a4ce-0049d9845350",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edf32438-f70e-4e27-a4ce-0049d9845350",
    "outputId": "4ea5eaea-1b68-4545-c57e-ecac93a5c02d"
   },
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "heart_failure_data = df.to_numpy()\n",
    "\n",
    "# Create feature matrix and target vector\n",
    "X = heart_failure_data[:,:2]   #all rows (:) and the first two columns (:2) of heart_failure_data\n",
    "y = heart_failure_data[:,2]    #all rows (:) and only the third column (2) of heart_failure_data.\n",
    "\n",
    "\n",
    "print('Feature matrix X dimensions: ', X.shape)\n",
    "print('Target vector y dimensions: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b74e6c-8f28-4ea3-869a-54dd89d7edc2",
   "metadata": {
    "id": "07b74e6c-8f28-4ea3-869a-54dd89d7edc2"
   },
   "source": [
    "## Plot data\n",
    "\n",
    "First, let's plot the data. The function takes two inputs:\n",
    "\n",
    "- Here, X is expected to be a 2D array with two columns representing two features (EF and GLS), and\n",
    "\n",
    "- y is expected to be a 1D array representing two classes: Healthy (0) and Heart Failure (1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae6166-9c71-4c34-ae1a-1e5af84ffd2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "c1ae6166-9c71-4c34-ae1a-1e5af84ffd2b",
    "outputId": "cef29246-b7da-4cc2-fb04-23366d31d032"
   },
   "outputs": [],
   "source": [
    "# This function will plot the heart failure data\n",
    "# We will plot the first feature (EF) on the x-axis and the second feature (GLS) on the y-axis\n",
    "def PlotData(X, y):\n",
    "\n",
    "    # Plot class 0 (all the data points that are classified as 'Healthy' (class 0))\n",
    "    # X[y==0]: This would give you all the rows in X where y is 0. (y==0 is a mask, it is true when y==0)\n",
    "    # X[y==0,0]: This gives you all the values in the first column of X for the rows where y is 0.\n",
    "    # X[y==0,1]: This gives you all the values in the second column of X for the rows where y is 0.\n",
    "    plt.plot(X[y==0,0], X[y==0,1], 'bo', alpha=0.75, markeredgecolor='k', label = 'Healthy')\n",
    "\n",
    "    # Plot class 1 ()plotting all the data points that are classified as 'Heart Failure'\n",
    "    plt.plot(X[y==1,0], X[y==1,1], 'rd', alpha=0.75, markeredgecolor='k', label = 'Heart Failure')\n",
    "\n",
    "    # Annotate the plot\n",
    "    plt.title('Diagnosis of Heart Failure')\n",
    "    plt.xlabel('EF')\n",
    "    plt.ylabel('GLS')\n",
    "    plt.legend()\n",
    "\n",
    "# Call the function to plot the dataset\n",
    "PlotData(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b4516-654d-4d65-be73-414c63c95b60",
   "metadata": {
    "id": "129b4516-654d-4d65-be73-414c63c95b60"
   },
   "source": [
    "## Standardize Data\n",
    "\n",
    "We'll use [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to standardize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439bddd-3a98-4123-b8b8-59e30801d9dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "6439bddd-3a98-4123-b8b8-59e30801d9dd",
    "outputId": "e99a3262-4b0d-4f81-865e-767afad3bc98"
   },
   "outputs": [],
   "source": [
    "# Create an object to scale the features to have zero mean and unit variance\n",
    "# We don't need to do this for all models, but let's do it here to be consistent\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a feature matrix containing EF and GLS\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Plot the scaled data using PlotData function that we defined above\n",
    "PlotData(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i6yo8_XUFPHc",
   "metadata": {
    "id": "i6yo8_XUFPHc"
   },
   "source": [
    "### **Feature Scaling**\n",
    "\n",
    " In many machine learning algorithms, it's beneficial to have **features that are on a similar scale**. This is because algorithms, such as gradient descent, will converge faster, and models can be more accurately trained when features are standardized.\n",
    "\n",
    " In machine learning, it is necessary to bring all the features to a common scale. **The scaling of features ensures that a feature with a relatively higher magnitude will not govern or control the trained model.**\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-3-Classification-models/imgs/feature_scaling.webp' width=300px>\n",
    "\n",
    "[source](https://medium.com/nerd-for-tech/why-feature-scaling-or-standardization-is-important-in-machine-learning-aaba175b664)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**StandardScaler**\n",
    "\n",
    "To help with this, we will be using the StandardScaler from the scikit-learn library to standardize our features. What standardizing does is **it transforms the features to have a mean of 0 and a standard deviation of 1**. In more simple terms, it makes our dataset's feature values more comparable to each other by bringing them onto a similar scale, which, in turn, aids in improving the performance of our machine learning model.\n",
    "\n",
    "Utilizing StandardScaler is a common preprocessing step to ensure that all of our features are treated equally while training the model. This process **doesn't alter the shape of each feature's distribution**; **it just relocates the distribution to have a mean value of zero and scales it to have a standard deviation of one**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9Gr0nBD8Hle",
   "metadata": {
    "id": "f9Gr0nBD8Hle"
   },
   "source": [
    "When you have a moment to unwind, I highly recommend checking out this intresting article. Enjoy!\n",
    "\n",
    "[Scale, Standardize, or Normalize with Scikit-Learn](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4153c8-4835-4165-9cd0-102ff0fb7391",
   "metadata": {
    "id": "9b4153c8-4835-4165-9cd0-102ff0fb7391"
   },
   "source": [
    "## Creating training and test sets\n",
    "\n",
    "We'll create training and test sets that we'll use for each example. For these examples, we'll just split up the data samples randomly, with 60% in the training set and 40% in the test set. A more common division would be (80%,20%) but since our **dataset is small**, we'll use **more in the test set**. We'll use the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)  function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DlM8DxkFA14x",
   "metadata": {
    "id": "DlM8DxkFA14x"
   },
   "source": [
    "<font color=blue>**Importing train_test_split**</font>\n",
    "\n",
    "\n",
    "Before running the code, you need to import the function from scikit-learn. You would have a line like this somewhere above in your script:\n",
    "\n",
    "<font color=blue>**from sklearn.model_selection import train_test_split**</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeddbf8-6575-4f8b-a660-cdbf6ff8a32a",
   "metadata": {
    "id": "aaeddbf8-6575-4f8b-a660-cdbf6ff8a32a"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "# Using a fixed random_state for consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KydJ5ZOaAGH5",
   "metadata": {
    "id": "KydJ5ZOaAGH5"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "<font color=blue>**train_test_split**</font>\n",
    "\n",
    "<font color=blue>**X, y:**</font>  These are your **feature matrix** and **label array**, respectively.\n",
    "\n",
    "<font color=blue>X</font>  contains the data for your features, and\n",
    "\n",
    "**<font color=blue>y</font>  contains the labels associated with each row of X**.\n",
    "\n",
    "<font color=blue>**test_size=0.4:**</font>  \n",
    "\n",
    "This argument specifies that 40% of the data will be used as the test set, and the remaining 60% will be used as the training set.\n",
    "\n",
    "<font color=blue>**random_state=0:**</font>\n",
    "\n",
    "This argument sets the random seed for the split. Using a **fixed seed** (like 0) ensures that if you run your script multiple times, **you'll get the same split each time**, which can be helpful for **debugging and comparing** different models.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<font color=blue>Output</font>\n",
    "\n",
    "The <font color=blue>train_test_split</font> function returns four arrays:\n",
    "\n",
    "<font color=blue>X_train</font>: The subset of <font color=blue>X</font> to be used for training.\n",
    "\n",
    "<font color=blue>X_test</font>: The subset of <font color=blue>X</font> to be used for testing.\n",
    "\n",
    "<font color=blue>y_train</font>: The subset of <font color=blue>y</font> corresponding to <font color=blue>X_train</font>.\n",
    "\n",
    "<font color=blue>y_test</font>: The subset of <font color=blue>y</font> corresponding to <font color=blue>X_test</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0682c83-a574-4018-95d1-284f7161b39c",
   "metadata": {
    "id": "f0682c83-a574-4018-95d1-284f7161b39c"
   },
   "source": [
    "## Perceptron\n",
    "\n",
    "Here, you are using the Perceptron model, **a type of linear classifier** that works well for **binary classification** problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706829c-a3ca-487d-9947-84713f86aa46",
   "metadata": {
    "id": "8706829c-a3ca-487d-9947-84713f86aa46"
   },
   "source": [
    "### Fit the model\n",
    "This code fits the [Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html) model to the training data.\n",
    "\n",
    "In machine learning, \"fitting the model\" refers to the **process of training the model using a dataset**. During this process, the model learns the underlying patterns in the data, which it later uses to make predictions on new, unseen data.\n",
    "\n",
    "Note that the Perceptron model is the same as the [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) function with **SGDClassifier**(loss=\"perceptron\", eta0=1, learning_rate=\"constant\", penalty=None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3e72a-3e1e-4e5c-bd4b-b448b9701524",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "fcf3e72a-3e1e-4e5c-bd4b-b448b9701524",
    "outputId": "51c70196-1eba-4aa2-b886-71371d79352c"
   },
   "outputs": [],
   "source": [
    "# Create and fit the model\n",
    "p_model = Perceptron(max_iter=100, eta0=0.2, random_state=0)\n",
    "p_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t_iJ7ZqxMMfB",
   "metadata": {
    "id": "t_iJ7ZqxMMfB"
   },
   "source": [
    "**Elaboration on code:**\n",
    "\n",
    "Below, we are elaborating on the different components involved in this process and the parameters you are using:\n",
    "\n",
    "<font color=blue>**Perceptron(max_iter=100, eta0=0.2, random_state=0)**</font>\n",
    "\n",
    "<font color=blue>**max_iter=100:**</font>\n",
    "\n",
    "This parameter specifies the **maximum number of passes (or iterations) over the training dataset**, also known as **epochs**. In this case, it is set to 100, meaning the algorithm will go through the training dataset up to 100 times to **fine-tune the model's weights**.\n",
    "\n",
    "<font color=blue>**eta0=0.2:**</font>  \n",
    "\n",
    "Here, eta0 is the learning rate, a hyperparameter that determines the step size during the weight update process in each iteration. A smaller learning rate (like 0.2) means that the model will learn slowly and might require more epochs, but it can help in reaching a more accurate solution.\n",
    "  \n",
    "<font color=blue> **random_state=0:**</font>   \n",
    "\n",
    "Setting a random_state ensures that the splits you generate are reproducible. Scikit-learn uses random permutations to generate the splits. The random state that you provide is used as a seed to the random number generator, ensuring that you get the same split each time you run the script.\n",
    "\n",
    "<font color=blue> **p_model.fit(X_train, y_train)**</font>\n",
    "\n",
    "This line of code **initiates the actual training of the Perceptron model** using the **training dataset** comprised of **X_train (feature matrix) and y_train (target vector)**.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5164537c-3694-4096-9e6a-fd238bf61072",
   "metadata": {
    "id": "5164537c-3694-4096-9e6a-fd238bf61072"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "We'll perform the same basic analysis for each model. First, we'll show the **confusion matrix** for the test set. Then we'll calculate several **useful scores**. This will help to evaluate the **performance** of each model and also to assess how much **overfitting** we have. Next, we'll also generate some interesting plots for each model.\n",
    "\n",
    "We'll use the [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and the [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function. We'll use the [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) to calculate the sensitivity specificity.\n",
    "\n",
    "Note that in binary classification, the recall of the positive class is also known as “**sensitivity**”; the recall of the negative class is “**specificity**”.\n",
    "\n",
    "In our example:\n",
    "- Negative: HF = 0 = healthy\n",
    "- Positive: HF = 1 = heart failure\n",
    "\n",
    "An alternative is to use the [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) function. This will return the recall, precision and F1 score on all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XdiqLLE-O1Lw",
   "metadata": {
    "id": "XdiqLLE-O1Lw"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**A Quick Refresher on Previously Covered Material:**\n",
    "\n",
    "A **confusion matrix** is a table that you create using (TN,TP,FN,FP) four values to understand the performance of the diagnostic test.\n",
    "\n",
    "**Accuracy** is the proportion of the total number of predictions that were correct.\n",
    "\n",
    "**Recall** (also known as sensitivity or true positive rate) is the proportion of actual positive cases that were identified correctly.\n",
    "\n",
    "the **specificity** (or true negative rate) is the proportion of actual negative cases that were identified correctly.\n",
    "\n",
    "**Sensitivity** (Recall for the positive class) would tell us how well the test identifies heart failure.\n",
    "\n",
    "**Specificity** (Recall for the negative class) would tell us how well the test identifies healthy individuals.\n",
    "\n",
    "So, by looking at these metrics individually and together, the doctor can get a sense of **how well the diagnostic test performs** and where it might have weaknesses. It helps to ensure that the test is trustworthy and to understand the kind of mistakes it tends to make **(whether it is more likely to misdiagnose healthy individuals or fail to identify true cases of heart failure)**.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kh7xEKM2MhEL",
   "metadata": {
    "id": "Kh7xEKM2MhEL"
   },
   "source": [
    "**EvaluateModel function**\n",
    "\n",
    "The EvaluateModel function you provided is designed to **evaluate a given model on both the training and test sets**.\n",
    "\n",
    "It calculates accuracy, sensitivity (recall), and specificity, then it **prints these metrics for both datasets**. Additionally, the function visually displays the confusion matrix for the test set using a **heatmap**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HrWOP2jMM-sv",
   "metadata": {
    "id": "HrWOP2jMM-sv"
   },
   "source": [
    "**Don't forget to include the import ones**\n",
    "\n",
    "Ensure you have the necessary imports at the beginning of your script:\n",
    "\n",
    "we already did it somewhere above:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "**Seaborn library in Python.**\n",
    "\n",
    "Seaborn is a powerful data visualization library based on Matplotlib. It provides a high-level interface for creating attractive statistical graphics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e9805-c303-4063-be3b-1e65e5dac266",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "5b6e9805-c303-4063-be3b-1e65e5dac266",
    "outputId": "619f5109-96dc-48a6-ac30-e66cf1f608f1"
   },
   "outputs": [],
   "source": [
    "def EvaluateModel(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Calculate and print metrics for the training set\n",
    "\n",
    "    #predict the labels for the training set (X_train) using\n",
    "    #the trained model and store the predictions in y_train_pred.\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    #calculates the accuracy of the model on the training set using the\n",
    "    #accuracy_score function. Accuracy measures the proportion of correct\n",
    "    #predictions out of all predictions.\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    #calculates the sensitivity (or recall) for the model on the training set.\n",
    "    #Sensitivity measures the proportion of actual positive cases\n",
    "    #(labelled as 1 in this context) that were correctly identified by the model.\n",
    "    train_sensitivity = recall_score(y_train, y_train_pred, pos_label=1)\n",
    "    #Specificity measures the proportion of actual negative cases\n",
    "    #(labelled as 0 in this context) that were correctly identified by the model.\n",
    "    #It's calculated similarly to sensitivity, but by setting pos_label=0.\n",
    "    train_specificity = recall_score(y_train, y_train_pred, pos_label=0)\n",
    "    #This line prints the calculated metrics with a precision of two decimal places.\n",
    "    print('Training set: Accuracy = {:0.2f} Sensitivity = {:0.2f} Specificity = {:0.2f}'.format(train_accuracy, train_sensitivity, train_specificity))\n",
    "\n",
    "    # Calculate and print metrics for the test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_sensitivity = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    test_specificity = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    print('Test set: Accuracy = {:0.2f} Sensitivity = {:0.2f} Specificity = {:0.2f}'.format(test_accuracy, test_sensitivity, test_specificity))\n",
    "\n",
    "    # Display the confusion matrices for the training and test sets\n",
    "\n",
    "    plt.figure(figsize=(4,2)) # Sets the size of the whole figure, including both subplots\n",
    "\n",
    "    # First, show the confusion matrix for the training set\n",
    "    plt.subplot(121) # Left subplot (1 = rows of figure, 2 = columns of figure, 1 = position of this subplot)\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    sns.heatmap(cm_train, annot=True)\n",
    "    plt.title('Training set')\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "\n",
    "    # Next, show the confusion matrix for the test set\n",
    "    plt.subplot(122) # Right subplot (1 = rows of figure, 2 = columns of figure, 2 = position of this subplot)\n",
    "    \n",
    "    #This line uses the confusion_matrix function to generate the confusion matrix\n",
    "    #for the true labels (y_test) and the predicted labels (y_test_pred).\n",
    "    #The result is stored in the cm variable.\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    #This line uses Seaborn's heatmap function to visualize the confusion matrix.\n",
    "    #The annot=True argument ensures that the individual values of the confusion\n",
    "    #matrix are annotated (i.e., displayed) on the heatmap.\n",
    "    sns.heatmap(cm_test, annot=True)\n",
    "    plt.title('Test set')\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    \n",
    "    plt.tight_layout() # Adds spacing between the subplots so they don't overlap\n",
    "    plt.show()\n",
    "\n",
    "EvaluateModel(p_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xeq3RyDCQPBw",
   "metadata": {
    "id": "xeq3RyDCQPBw"
   },
   "source": [
    "To run this code, **ensure you have the necessary libraries imported** which we did it in the beginning of the class.\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33532c2b-9bae-46ce-88e9-8922f4b959c7",
   "metadata": {
    "id": "33532c2b-9bae-46ce-88e9-8922f4b959c7"
   },
   "source": [
    "**What Do These Numbers Indicate?**\n",
    "\n",
    "We have better sensitivity and worse specificity.\n",
    "\n",
    "1. Our model is better at correctly **predicting that patients with heart disease have heart disease**, but is\n",
    "\n",
    "2. worse at correctly predicting that **patients without heart disease don't have heart disease**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10269e97-7b0e-49c5-ac1f-ed0eea7bb982",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "10269e97-7b0e-49c5-ac1f-ed0eea7bb982",
    "outputId": "da7d9df2-2b6a-4a68-dd18-0c2978aa85fc"
   },
   "outputs": [],
   "source": [
    "# This is an alternate function for evaluating the model results using the classification_report function\n",
    "\n",
    "def EvaluateModelClassificationReport(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Calculate and print classification report for the training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print('Classification report for training set:')\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "    # Calculate and print classification report for the test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print('Classification report for test set:')\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    # Display the confusion matrices\n",
    "    plt.figure(figsize=(4,2)) # Sets the size of the whole figure, including both subplots\n",
    "    plt.subplot(121) # Left subplot (1 = rows of figure, 2 = columns of figure, 1 = position of this subplot)\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    sns.heatmap(cm_train, annot=True)\n",
    "    plt.title('Training set')\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    plt.subplot(122) # Right subplot (1 = rows of figure, 2 = columns of figure, 2 = position of this subplot)\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    sns.heatmap(cm_test, annot=True)\n",
    "    plt.title('Test set')\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    plt.tight_layout() # Adds spacing between the subplots so they don't overlap\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "EvaluateModelClassificationReport(p_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a108bd6-4edf-4acb-bb5e-cd78995c1d81",
   "metadata": {
    "id": "6a108bd6-4edf-4acb-bb5e-cd78995c1d81"
   },
   "source": [
    "### Plot the model\n",
    "\n",
    "Let's also visualize the **decision boundary** itself. This specific visualization **only works because we have two features**. (In general, the decision boundary will be a hyperplane, so to use a similar visualization we would need to reduce the dimensionality of the features.) The result of the classification is plotted below. We'll also plot data points for the full dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940ad40-c808-47ae-b1b8-ba8df58cbded",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "a940ad40-c808-47ae-b1b8-ba8df58cbded",
    "outputId": "cc864c63-38ea-4164-a482-d4e2472193b9"
   },
   "outputs": [],
   "source": [
    "# plot the decision boundary for a linear model,\n",
    "#given that the model works on two features (2D space).\n",
    "\n",
    "def PlotDecisionBoundary(model, X, y):\n",
    "\n",
    "    # Plot the data\n",
    "    #This represents the true labels of each data point in a 2D space.\n",
    "    PlotData(X, y)\n",
    "\n",
    "    # Next, we will plot the decision boundary using the weights of the model\n",
    "\n",
    "    # Define y-coordinates\n",
    "    # We are just using the range (min and max) of the y-axis (GLS in this case)\n",
    "    x2 = np.array([X[:,1].min(), X[:,1].max()])\n",
    "\n",
    "\n",
    "    \"\"\" For a linear model, the decision boundary is determined by its weights.\n",
    "    The weights represent how much each feature contributes to the model's decision.\n",
    "     Here, w0 is the bias term, w1 is the weight for the first feature,\n",
    "     and w2 is the weight for the second feature. \"\"\"\n",
    "\n",
    "    # Find the weights\n",
    "    # w0 is the\n",
    "    # w1 is the weight for the first feature\n",
    "    # w2 is the weight for the second feature\n",
    "    # i.e. The decision boundary is function h(x) = w0 + w1*x_1 + w2*x_2 where x_1 and x_2 are our 2 features (EF, GLS)\n",
    "\n",
    "    w0 = model.intercept_[0]\n",
    "    w1 = model.coef_[0][0]\n",
    "    w2 = model.coef_[0][1]\n",
    "\n",
    "    # Define x-coordinates\n",
    "    # Notice that this equation is just a rearrangement of the function for the decision boundary\n",
    "    x1 = -(w0 + w2*x2)/w1\n",
    "    # Now the points (x1[0],x2[0]) and (x1[1],x2[1]) are two points on our decision boundary\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.plot(x1, x2, \"k-\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "PlotDecisionBoundary(p_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MXxreSkrieFN",
   "metadata": {
    "id": "MXxreSkrieFN"
   },
   "source": [
    "The line is our model's decision boundary between the two classes (healthy and heart failure)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fq4mCUADfVMg",
   "metadata": {
    "id": "Fq4mCUADfVMg"
   },
   "source": [
    "**A Gentle Guide to Model Parameters**\n",
    "\n",
    "If you're still finding your way around coding, no worries. These commands are simply picking out the key ingredients (parameters) from our trained model. With a bit more time, you'll feel right at home with them. Keep going!\"\n",
    "\n",
    "1. <font color=blue>**`w0 = model.intercept_[0]`**</font>:\n",
    "   - <font color=blue>**`model.intercept_`**</font>: For many linear models in libraries like `scikit-learn`, the `intercept_` attribute provides the bias term, often denoted as:\n",
    "     $$\n",
    "     b \\text{ or } w_0\n",
    "     $$\n",
    "     This represents the point where the decision boundary intersects the y-axis when all feature values are 0.\n",
    "   - **`[0]`**: This indexing is extracting the first (and often only) value from the `intercept_` attribute. For simple linear regression or binary classification, `intercept_` contains only one value. However, for multiclass problems, there might be multiple intercepts, one for each class.\n",
    "\n",
    "2. <font color=blue>**`w1 = model.coef_[0][0]`**</font>:\n",
    "   - <font color=blue>**`model.coef_`**</font>: This attribute provides the weights or coefficients of each feature in the model. In a linear equation, these weights determine how much each feature contributes to the output prediction.\n",
    "   - **`[0][0]`**: This indexing retrieves the weight of the first feature. The first `[0]` selects the set of coefficients for the first (or only, in the case of binary classification) class, and the second `[0]` picks out the coefficient for the first feature.\n",
    "\n",
    "3. <font color=blue>**`w2 = model.coef_[0][1]`**</font>:\n",
    "   - Here we are again referring to the <font color=blue>**`model.coef_`**</font> attribute.\n",
    "   - **`[0][1]`**: This indexing fetches the weight of the second feature. The first `[0]` once more chooses the set of coefficients for the first (or only) class, and the second `[1]` selects the coefficient for the second feature.\n",
    "\n",
    "In essence, these commands are pulling out the parameters of a linear decision boundary from a trained model. If you're familiar with the equation of a line:\n",
    "$$\n",
    "y = mx + b\n",
    "$$\n",
    "the `model.coef_` values correspond to the slope \\( m \\), and the `model.intercept_` is similar to the y-intercept \\( b \\). In the realm of the decision boundary for a linear classifier, these parameters define the boundary's orientation and position in the feature space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8218039a-dd95-4270-a2e4-e3ba0830d963",
   "metadata": {
    "id": "8218039a-dd95-4270-a2e4-e3ba0830d963"
   },
   "source": [
    "### **Confidence score**\n",
    "\n",
    "Let's show some more information instead of just the decision boundary. We can show confidence scores for predictions. In the case of the Perceptron model **the confidence score is simply proportional to the signed distance from the decision boundary.**\n",
    "\n",
    "In Scikit-Learn we use the model's **decision_function** method to find the confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4721e84-1895-4a5d-8a91-cfce3797f308",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "e4721e84-1895-4a5d-8a91-cfce3797f308",
    "outputId": "a1095313-d3f3-42ed-f0d5-2cb288426e33"
   },
   "outputs": [],
   "source": [
    "\n",
    "def PlotConfidenceScores(model, X, y, label=1):\n",
    "\n",
    "    \"\"\"Plots the confidence scores or probabilities for each sample being classified\n",
    "    as the given label.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained classifier.\n",
    "    - X: The data samples.\n",
    "    - y: The true labels of the samples.\n",
    "    - label: The class label for which we want to compute the confidence scores (default is 1).\n",
    "    \"\"\"\n",
    "    # x1 and x2 are created as linspace arrays. They span the range of the data samples in both the dimensions.\n",
    "    \"\"\"Create 1D arrays of points for each feature (we have 2 features in this example)\n",
    "    It simply finds the lowest and highest values of our first feature\n",
    "    and our line should go between these points.\"\"\"\n",
    "    x1 = np.linspace(X[:,0].min(), X[:,0].max(), 1000)\n",
    "    \"\"\"#It's creating 1,000 evenly spaced points between the lowest and highest\n",
    "    values of our second feature (GLS).\n",
    "    Why 1,000? Well, having lots of points makes the line we draw\n",
    "    (our decision boundary) look really smooth.\"\"\"\n",
    "    x2 = np.linspace(X[:,1].min(), X[:,1].max(), 1000).T # Note the transpose\n",
    "\n",
    "    # Create 2D arrays that hold the coordinates in 2D feature space\n",
    "    #  then generates two 2D arrays,\n",
    "    #representing all combinations of x1 and x2 in the feature space.\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "\n",
    "    # Flatten x1 and x2 to 1D vectors and concatenate into a feature matrix\n",
    "    # The 2D arrays are reshaped to 1D and concatenated\n",
    "    #to form a matrix Xp which represents all the points in the 2D feature space.\n",
    "    Xp = np.c_[x1.ravel(), x2.ravel()]\n",
    "\n",
    "    # Predict confidence scores for the whole feature space\n",
    "    df = model.decision_function(Xp)\n",
    "\n",
    "    # Select the class\n",
    "    # Note that the confidence scores are >0 for class 1 (positive class)\n",
    "    # If we want to show the confidence scores for class 0 (negative class) we multiply by -1\n",
    "    #to flip the interpretation\n",
    "    if label == 0:\n",
    "        df *= -1\n",
    "\n",
    "    # Reshape to 2D\n",
    "    # is adjusting the shape of the array df to match the shape of x1.\n",
    "\n",
    "    df = df.reshape(x1.shape)\n",
    "\n",
    "    # Plot using contourf to generate colored regions\n",
    "    plt.contourf(x1, x2, df, cmap = 'summer')\n",
    "\n",
    "    # Add a colorbar\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Also, plot the line where the confidence score == 0, i.e. the decision boundary\n",
    "    plt.contour(x1, x2, df, levels=[0], colors='k')\n",
    "\n",
    "    # Also plot the data\n",
    "    PlotData(X, y)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "PlotConfidenceScores(p_model, X, y, label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q_K46Ma9mH3z",
   "metadata": {
    "id": "q_K46Ma9mH3z"
   },
   "source": [
    "If you want to know more about coloring commands:\n",
    "\n",
    "**plt.contourf:** Plots filled contours. The regions with different colors represent regions of varying confidence levels. The colormap 'summer' is used.\n",
    "\n",
    "**plt.colorbar:** Adds a colorbar to the side to indicate the values of the confidence scores corresponding to the colors.\n",
    "\n",
    "**plt.contour:** Draws the decision boundary (the line where confidence score == 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dee660-47ae-4226-a082-6433046711a3",
   "metadata": {
    "id": "f3dee660-47ae-4226-a082-6433046711a3"
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The next model we'll try is the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea2e19-7c80-4641-926f-cf0ff589bb30",
   "metadata": {
    "id": "35ea2e19-7c80-4641-926f-cf0ff589bb30"
   },
   "outputs": [],
   "source": [
    "# Here's the code for the logistic regression classifier\n",
    "\n",
    "# Create and fit the model\n",
    "logreg_model = LogisticRegression(random_state=0)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "logreg_pred = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b5bc5-7f2f-42b1-baab-719c35fb9d65",
   "metadata": {
    "id": "a02b5bc5-7f2f-42b1-baab-719c35fb9d65"
   },
   "source": [
    "We'll use the same code to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53009ff5-427a-4261-9376-55ab35c33715",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "53009ff5-427a-4261-9376-55ab35c33715",
    "outputId": "fab02870-b935-467c-bdfa-1b0707880682"
   },
   "outputs": [],
   "source": [
    "EvaluateModel(logreg_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c1a1c-0bfe-4a77-afe4-58f9cdb96a79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "7c8c1a1c-0bfe-4a77-afe4-58f9cdb96a79",
    "outputId": "d13d4b99-a314-47a7-a305-3cff66806086"
   },
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "PlotDecisionBoundary(logreg_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b3d93-d1e2-4385-864e-863475104a5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "ec8b3d93-d1e2-4385-864e-863475104a5a",
    "outputId": "a263089e-9d8b-427c-84e9-863a8606dbf7"
   },
   "outputs": [],
   "source": [
    "# Plot the confidence scores\n",
    "PlotConfidenceScores(logreg_model, X, y, label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43378df-3692-4e5e-9116-767c3e706255",
   "metadata": {
    "id": "c43378df-3692-4e5e-9116-767c3e706255"
   },
   "source": [
    "An **advantage** of the LogisticRegression model compared with the Perceptron is that **we can estimate probabilities** for each class.\n",
    "\n",
    "This is more useful than just using **the distance from the decision boundary as a confidence score.** We'll plot the probabilities for each class using [predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba) method of the model.\n",
    "\n",
    "About the **PlotProbabilities** function:\n",
    "\n",
    "The function PlotProbabilities is designed to visualize how a **linear model predicts the probability of a particular class label for a given set of 2D data**. The resultant plot provides a color map, where colors correspond to the model's predicted probability that a point belongs to the class of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aeed11-42b9-4c96-b7ed-b55eadf5155f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "03aeed11-42b9-4c96-b7ed-b55eadf5155f",
    "outputId": "5f4822bb-9a30-4284-e93c-7fef8184c8a8"
   },
   "outputs": [],
   "source": [
    "# Plot the probabilities for a linear model\n",
    "# This function is only for linear models with 2 features\n",
    "\n",
    "def PlotProbabilities(model, X, y, label=1):\n",
    "\n",
    "    \"\"\" The function PlotProbabilities is defined with four parameters:\n",
    "\n",
    "    model: This is the trained linear model.\n",
    "    X: The data points with two features.\n",
    "    y: The actual labels of these data points.\n",
    "    label: The class for which you want to plot the probabilities (default is 1). \"\"\"\n",
    "\n",
    "    # Create 1D arrays of points for each feature (we have 2 features in this example)\n",
    "    \"\"\" The lines involving x1, x2, and np.meshgrid set up a grid that spans\n",
    "    the entire feature space of X. Essentially, you're creating a dense grid of\n",
    "    potential data points to cover the entire range of your data in both dimensions. \"\"\"\n",
    "    x1 = np.linspace(X[:,0].min(), X[:,0].max(), 1000)\n",
    "    x2 = np.linspace(X[:,1].min(), X[:,1].max(), 1000).T # Note the transpose\n",
    "\n",
    "    # Create 2D arrays that hold the coordinates in 2D feature space\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "\n",
    "    # Flatten x1 and x2 to 1D vectors and concatenate into a feature matrix\n",
    "    Xp = np.c_[x1.ravel(), x2.ravel()]\n",
    "\n",
    "    \"\"\"Predicting Probabilities:\n",
    "    The model.predict_proba(Xp) function predicts the probabilities for all the data\n",
    "    points in the grid Xp. The result, proba, has the probabilities for each class.\n",
    "\n",
    "    If there are two classes (0 and 1),\n",
    "    then proba[:,0] gives the probabilities for class 0, and proba[:,1] for class 1.\n",
    "\n",
    "    The line p = proba[:, label] selects the probabilities for the desired class\n",
    "    (based on the label parameter).\"\"\"\n",
    "\n",
    "    # Predict probabilities for the whole feature space\n",
    "    # Note the predict_proba function! This gives us the probabilities\n",
    "    proba = model.predict_proba(Xp)\n",
    "\n",
    "    # Select the class\n",
    "    # Note this is different from how we selected the class with the decision boundary function\n",
    "    p = proba[:, label]\n",
    "\n",
    "    # Reshape to 2D\n",
    "    #The probabilities in p are reshaped to a 2D structure to match the grid format,\n",
    "    #so they can be plotted against the grid.\n",
    "    p = p.reshape(x1.shape)\n",
    "\n",
    "    # Plot using contourf\n",
    "    # The plt.contourf function creates a filled contour plot. This will color\n",
    "    #the grid based on the probabilities in p, using the 'summer' colormap.\n",
    "    plt.contourf(x1, x2, p, cmap = 'summer')\n",
    "\n",
    "    # Add colorbar\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Also, plot the line where the probability == 0.5\n",
    "    # adds a black contour line where the predicted probability is 0.5.\n",
    "    #This is effectively the decision boundary of the model.\n",
    "    plt.contour(x1, x2, p, levels=[0.5], colors='k')\n",
    "\n",
    "    # Also plot the data\n",
    "    # plots the original data points (X, y) onto the visualization.\n",
    "    PlotData(X, y)\n",
    "\n",
    "PlotProbabilities(logreg_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YC7fEnWjn_V-",
   "metadata": {
    "id": "YC7fEnWjn_V-"
   },
   "source": [
    "**Once and foever about the bwlow commands:**\n",
    "\n",
    "Imagine you're laying out a big sheet of graph paper to sketch your data. Each box in the graph paper represents a location where you want to know what your model thinks.\n",
    "\n",
    "<font color=blue>**x1 = np.linspace(X[:,0].min(), X[:,0].max(), 1000)**:</font>\n",
    "Here, you're looking at all the data you have and finding the smallest and biggest values for the first feature (like the horizontal or 'X' direction of the graph paper).\n",
    "Then, you're marking out 1000 evenly spaced points between these extremes. It's like you're putting 1000 tiny tick marks on the bottom edge of your graph paper to know where you'll sketch.\n",
    "\n",
    "<font color=blue>**x2 = np.linspace(X[:,1].min(), X[:,1].max(), 1000).T**:</font>\n",
    "\n",
    "Now, you're doing the same for the second feature, which is like the vertical or 'Y' direction of the graph paper.\n",
    "Again, you're finding the smallest and biggest values. Then, marking out 1000 evenly spaced points between these. These are like the tick marks on the side of your graph paper.\n",
    "Now, with these two sets of tick marks (x1 and x2), you have a framework or grid. Using this grid, you can check every point to see what your model thinks about it. The .T at the end is just a technical detail to make sure everything lines up correctly when we use these values later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7dd539-7985-4ab7-9c76-b08c691803e8",
   "metadata": {
    "id": "af7dd539-7985-4ab7-9c76-b08c691803e8"
   },
   "source": [
    "## Support Vector Classifier\n",
    "\n",
    "#### Support vector classification\n",
    "\n",
    "Now we'll explore the Support Vector Classifier (SVC). Linear binary SVC is very similar to the perceptron and logistic regression in the sense that **it finds the optimal hyperplane to separate two classes**. These methods, however, have different objectives through which they decide what is the optimal decision boundary.\n",
    "\n",
    "There are three different SVC classifiers in `sklearn` library:\n",
    "\n",
    "1. [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) implements linear classifier optimised for performance but does not support the **kernel trick**.\n",
    "\n",
    "2. [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) implements SVC with kernel trick. Setting `kernel='linear'` produces the same result as LinearSVC but is less efficient in terms of computational time. Setting `kernel='rbf'` produces **non-linear classifier with Gaussian kernel**.\n",
    "\n",
    "3. [SGDclassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) implements various classifiers that are optimised using **stochastic gradient descent**. Its default setting for loss function is `loss='hinge'` which is another implementation of a linear SVC.\n",
    "\n",
    "In practice, the SVC model may take a **long time** to run for very large datasets, so the **LinearSVC or SGDclassifier** may be a better choice. On the other hand, the SVC model supports the kernel trick and makes it easy to obtain and visualize the support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d66b9-49bd-4a65-a81b-1e69e4269b5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "af8d66b9-49bd-4a65-a81b-1e69e4269b5a",
    "outputId": "27a3dd49-942f-4b1e-85bb-330fa901c64f"
   },
   "outputs": [],
   "source": [
    "# First, a LinearSVC model\n",
    "# dual='auto' will select dual=False unless n_samples<n_features and other conditions are met\n",
    "# With dual=False the optimization variable has dimension=dimension of n_features (dual=True it is equal to n_samples)\n",
    "# Note that when dual=False, random_state has no effect since the algorithm is not random\n",
    "linearsvc_model = LinearSVC(dual= False, random_state=0)\n",
    "linearsvc_model.fit(X_train, y_train)\n",
    "linearsvc_pred = linearsvc_model.predict(X_test)\n",
    "\n",
    "# Results\n",
    "EvaluateModel(linearsvc_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lS9jLh7zuqIz",
   "metadata": {
    "id": "lS9jLh7zuqIz"
   },
   "source": [
    "**Primal vs. Dual Formulation:**\n",
    "\n",
    "In the context of the LinearSVC classifier from the scikit-learn library, the dual parameter determines which formulation of the problem the algorithm should solve – the primal or the dual.\n",
    "\n",
    "**Let's go deeper:**\n",
    "\n",
    "Primal vs. Dual Formulation:\n",
    "SVM (Support Vector Machine) optimization problems can be expressed in two forms: primal and dual.\n",
    "\n",
    "- The **primal problem** is formulated in terms of feature space (based on the number of features),\n",
    "\n",
    "- while the **dual problem** is formulated in terms of data points (based on the number of samples).\n",
    "\n",
    "**Why the Dual?:**\n",
    "\n",
    "For certain types of datasets and kernels, solving the dual problem can be more efficient than solving the primal. **Specifically**, when the number of samples is less than the number of features, the dual form can be more efficient.\n",
    "\n",
    "**The dual parameter in LinearSVC:**\n",
    "\n",
    "When you set **dual=True**, the algorithm solves the dual form of the SVM problem.\n",
    "\n",
    "When you set **dual=False**, it solves the primal form.\n",
    "\n",
    "When you set **dual='auto'**, as in your provided code, the algorithm will automatically choose which form to solve **based on the dimensions of the input data. **\n",
    "\n",
    "Specifically, **it will prefer the primal form (dual=False) unless the number of samples is less than the number of features and some other conditions are met.**\n",
    "In practice, this parameter provides flexibility to the algorithm to choose the most efficient method based on the shape and structure of the provided dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc66f6e-413e-45bb-b2e7-ebaff2a72f3d",
   "metadata": {
    "id": "cfc66f6e-413e-45bb-b2e7-ebaff2a72f3d"
   },
   "outputs": [],
   "source": [
    "# This function is for plotting the different SVC models\n",
    "# It is similar to PlotProbilities, but can also plot the support vectors\n",
    "# If plotSV=True, plot the support vectors with circles\n",
    "#    Note that LinearSVC does not provide the support vectors, so we can't easily plot them\n",
    "# If plotDF=True, plot the confidence scores using a contour plot\n",
    "# If plotProb=True, plot the probabilities using a contour plot\n",
    "#    Note that LinearSVC does not provide probabilities\n",
    "\n",
    "def PlotSVC(model, X, y, label=1, plotSV=False, plotDF=False, plotProba=False):\n",
    "\n",
    "    # Create 1D arrays of points for each feature (we have 2 features in this example)\n",
    "    x1 = np.linspace(-2.5, 2, 1000)\n",
    "    x2 = np.linspace(-3, 3.5, 1000).T # note the transpose\n",
    "\n",
    "    # Create 2D arrays that hold the coordinates in 2D feature space\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "\n",
    "    # Flatten x1 and x2 to 1D vectors and concatenate into a feature matrix\n",
    "    Xp = np.c_[x1.ravel(), x2.ravel()]\n",
    "\n",
    "    # Plot decision function\n",
    "    if plotDF:\n",
    "        # Predict confidence scores for the whole feature space\n",
    "        df = model.decision_function(Xp)\n",
    "\n",
    "        # Reshape to 2D\n",
    "        df = df.reshape(x1.shape)\n",
    "\n",
    "        # Select the class\n",
    "        # Note that the confidence scores are >0 for class 1 (positive class)\n",
    "        # If we want to show the confidence scores for class 0 (negative class) we multiply by -1\n",
    "        # to flip the interpretation\n",
    "        if label == 0:\n",
    "            df *= -1\n",
    "\n",
    "        # Zero contour is decision boundary, isolines +-1 are the margins\n",
    "        contour = plt.contour(x1, x2, df, levels=[-1,0,1], colors='k', linestyles=('dashed', 'solid', 'dashed'))\n",
    "        plt.clabel(contour, inline=1, fontsize=14)\n",
    "\n",
    "        \"\"\"Predicting Probabilities:\n",
    "        The model.predict_proba(Xp) function predicts the probabilities for all the data\n",
    "        points in the grid Xp. The result, proba, has the probabilities for each class.\n",
    "\n",
    "        If there are two classes (0 and 1),\n",
    "        then proba[:,0] gives the probabilities for class 0, and proba[:,1] for class 1.\n",
    "\n",
    "        The line p = proba[:, label] selects the probabilities for the desired class\n",
    "        (based on the label parameter).\"\"\"\n",
    "\n",
    "    # Plot probabilities\n",
    "    # This checks if we should plot probability contours.\n",
    "    if plotProba:\n",
    "\n",
    "        # Predict probabilities for the whole feature space\n",
    "        # estimates the probability for each class at each point in the\n",
    "        # feature space represented by Xp.\n",
    "        proba = model.predict_proba(Xp)\n",
    "\n",
    "        # Select the class\n",
    "        # The probabilities for the class specified by label are extracted.\n",
    "        p = proba[:, label]\n",
    "\n",
    "        # Reshape to 2D\n",
    "        # reshaped to match the shapes of x1 and x2\n",
    "        p = p.reshape(x1.shape)\n",
    "\n",
    "        # Plot using contourf\n",
    "        # # These probabilities are then plotted using a filled contour plot with plt.contourf()\n",
    "        plt.contourf(x1, x2, p, cmap = 'summer')\n",
    "\n",
    "        # Add colorbar\n",
    "        # A colorbar is added to the plot to provide a reference for the probability values.\n",
    "        plt.colorbar()\n",
    "\n",
    "        # Also, plot the line where the probability == 0.5\n",
    "        # The line where the estimated probability is exactly 0.5 is also\n",
    "        # plotted, which can be considered as the decision boundary.\n",
    "        plt.contour(x1, x2, p, levels=[0.5], colors='k')\n",
    "\n",
    "    # Plot support vectors\n",
    "    \"\"\" condition on plotSV:\n",
    "    This checks if we should plot the support vectors.\n",
    "    Support vectors are the data points that define the margin of the SVM. They are the most challenging data points for the SVM, as they are the closest to the decision boundary.\n",
    "    These are plotted using large pink dots.\"\"\"\n",
    "    if plotSV:\n",
    "        svs = model.support_vectors_\n",
    "        plt.scatter(svs[:, 0], svs[:, 1], s=180, facecolors='pink', label = 'Support vectors', edgecolor='k')\n",
    "\n",
    "    # plot data\n",
    "    PlotData(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "euGhnK6JNvfF",
   "metadata": {
    "id": "euGhnK6JNvfF"
   },
   "source": [
    "**Appropriate imports**, e.g.,\n",
    "\n",
    "import matplotlib.pyplot as plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aef96f-41c5-4717-8e91-34d4a07da2f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "69aef96f-41c5-4717-8e91-34d4a07da2f2",
    "outputId": "93cf59b7-2e62-4c28-8f06-8ac4bf1b46bb"
   },
   "outputs": [],
   "source": [
    "# Plot boundary\n",
    "PlotSVC(linearsvc_model, X, y, plotSV=False, plotDF=True, plotProba=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cncdqaYOBid",
   "metadata": {
    "id": "0cncdqaYOBid"
   },
   "source": [
    "**PlotSVC**\n",
    "\n",
    "Based on the arguments:\n",
    "\n",
    "**linearsvc_model:** This is the trained SVC model we want to visualize.\n",
    "X: The dataset's features.\n",
    "y: The dataset's labels or targets.\n",
    "\n",
    "**plotSV**: A **boolean indicating** whether to plot the support vectors. It's set to False, so support vectors won't be plotted.\n",
    "\n",
    "**plotDF:** A boolean indicating whether to plot the decision function. Since it's set to True, the decision function will be plotted.\n",
    "\n",
    "**plotProba:** A boolean indicating whether to plot the probabilities. It's set to False, so probabilities won't be plotted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b3b3cb-0e58-4f8b-8547-b557618a0456",
   "metadata": {
    "id": "17b3b3cb-0e58-4f8b-8547-b557618a0456"
   },
   "source": [
    "## Support Vector Classifier\n",
    "\n",
    "Next we'll try the [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3291e6b-24cd-45e8-8e6b-071bd7563b10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "c3291e6b-24cd-45e8-8e6b-071bd7563b10",
    "outputId": "ec45ad6c-be14-4b64-957a-2c1459bbac21"
   },
   "outputs": [],
   "source": [
    "# A linear SVC using the SVC class (instead of LinearSVC)\n",
    "# probability=True will allow us to use predict_proba on the fitted model\n",
    "# You've explicitly set the kernel to 'linear', which means the SVM will use a\n",
    "# linear decision boundary. The probability=True argument ensures that the trained\n",
    "# model can provide probability estimates for predictions using the predict_proba() method.\n",
    "\n",
    "svc_model = SVC(kernel='linear', probability=True, random_state=0)\n",
    "# After fitting the model to your training data  (X_train, y_train)\n",
    "svc_model.fit(X_train, y_train)\n",
    "# you're making predictions on the test set with\n",
    "svc_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Results\n",
    "# Finally, you're evaluating the model using the EvaluateModel() function.\n",
    "EvaluateModel(svc_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d53862-b1b8-4a66-9da4-3b1f501734ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "e2d53862-b1b8-4a66-9da4-3b1f501734ac",
    "outputId": "18d45e4b-da96-48e1-a8a2-9e31c7c8249c"
   },
   "outputs": [],
   "source": [
    "# Plot probabilities and support vectors\n",
    "PlotSVC(svc_model, X, y, plotSV=True, plotDF=True, plotProba=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rYr35u_EPrC_",
   "metadata": {
    "id": "rYr35u_EPrC_"
   },
   "source": [
    "This above line of code is a call to the **PlotSVC() function**, which, based on our previous discussions, is intended for visualizing various characteristics of a **trained Support Vector** Machine (SVC) on a **2D feature space**.\n",
    "\n",
    "Given the arguments you've provided:\n",
    "\n",
    "**svc_model:** This is the trained linear SVC model you want to visualize.\n",
    "\n",
    "**X:** The dataset's features.\n",
    "\n",
    "**y:** The dataset's labels or targets.\n",
    "\n",
    "**plotSV:** A boolean indicating whether to plot the support vectors. Since it's set to True, the support vectors will be plotted as large dots on the visualization. These are crucial data points as they determine the decision boundary of the SVM.\n",
    "\n",
    "**plotDF:** A boolean indicating whether to plot the decision function. Since it's set to True, the decision boundary will be visualized on the plot.\n",
    "\n",
    "**plotProba:** A boolean indicating whether to plot the probabilities. It's set to False, so the probability contours will not be displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da9a12-5d30-4739-9872-0268c398343d",
   "metadata": {
    "id": "52da9a12-5d30-4739-9872-0268c398343d"
   },
   "source": [
    "## Support Vector Classifier with Kernel Trick\n",
    "\n",
    "The kernel trick we'll allow us to have a nonlinear boundary between the classes, instead of a simple line (or hyperplane)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0e1f0-80cd-45b5-9469-1afc5f4f1e93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "f8c0e1f0-80cd-45b5-9469-1afc5f4f1e93",
    "outputId": "f7268ec1-d14e-4545-b693-9db5d204dfbe"
   },
   "outputs": [],
   "source": [
    "# Create SVC model using the kernel trick\n",
    "kernelsvc_model = SVC(kernel='rbf', probability=True, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "kernelsvc_model.fit(X_train, y_train)\n",
    "EvaluateModel(kernelsvc_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797dafc7-0357-4576-a07f-eb0b6c6f1d2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "797dafc7-0357-4576-a07f-eb0b6c6f1d2e",
    "outputId": "8a6370bf-1d6e-49e1-e7ba-417dfafa1396"
   },
   "outputs": [],
   "source": [
    "# Plot decision boundary and margins\n",
    "PlotSVC(kernelsvc_model, X, y, plotSV=True, plotDF=True, plotProba=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FK9D1ePNbuaR",
   "metadata": {
    "id": "FK9D1ePNbuaR"
   },
   "source": [
    "**Kernel trick**\n",
    "\n",
    "The \"kernel trick\" is a technique used in machine learning, especially in the context of support vector machines (SVMs) and other kernelized models, to operate in a **high-dimensional feature space without explicitly computing the coordinates of the data in that space**.\n",
    "\n",
    "Essentially,\n",
    "\n",
    "- it allows algorithms to become more flexible and\n",
    "\n",
    "- capable of separating data that isn't linearly separable in its original space.\n",
    "\n",
    "Let's break this down with a simple explanation:\n",
    "\n",
    "**Kernel Functions:** These are mathematical functions that **take two inputs and output a single number**. The function is designed to quantify some form of similarity between the inputs.\n",
    "\n",
    "**High-Dimensional Space:** Sometimes, data that is not linearly separable in its original space can become separable when it is **mapped to a higher-dimensional space**.\n",
    "\n",
    "**Computational Efficiency:** Working directly in a high-dimensional space can be computationally intensive because it might require dealing with a very large number of features. The kernel trick helps to avoid this computational burden **by working in the original space but using the kernel function to implicitly work in the high-dimensional space**.\n",
    "\n",
    "**Support Vector Machines (SVMs):** SVMs are a kind of machine learning model often used for classification tasks. SVMs can use the **kernel trick to find the optimal hyperplane in the high-dimensional space**, which separates different classes in the data in such a way that **the margin between them is maximized.**\n",
    "\n",
    "**Common Kernels:**\n",
    "\n",
    "Some commonly used kernel functions include\n",
    "\n",
    "1. the linear kernel,\n",
    "\n",
    "2. polynomial kernel, and\n",
    "\n",
    "3. radial basis function (RBF) kernel,\n",
    "\n",
    "each having its own way of measuring similarity between data points.\n",
    "\n",
    "For example, imagine you have a dataset of two features that, when plotted on a graph, cannot be separated by a straight line. By using the kernel trick, you might find that if you add another dimension (making the graph 3D), you can now separate the data points perfectly with a plane. This \"trick\" essentially allows the SVM to find complex boundaries between classes without having to perform computationally expensive transformations on the data.\n",
    "\n",
    "[Explore further and learn about the various types of kernels](https://github.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/blob/main/kernel_trick.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b127e43-602a-4c19-a032-63b2ed57d0cb",
   "metadata": {
    "id": "6b127e43-602a-4c19-a032-63b2ed57d0cb"
   },
   "source": [
    "## Decision Tree\n",
    "\n",
    "Now let's check out the [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83e67e-18d5-477f-942a-5826aecb1fc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "6a83e67e-18d5-477f-942a-5826aecb1fc6",
    "outputId": "82669e98-09c1-4a03-c6a6-50df698daa49"
   },
   "outputs": [],
   "source": [
    "# Create and fit a DecisionTreeClassifier model\n",
    "# max_depth is the maximum depth of the tree\n",
    "tree_model = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
    "tree_model.fit(X_train, y_train)\n",
    "EvaluateModel(tree_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa07586-f155-42aa-84ca-5301c5e6b51b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "baa07586-f155-42aa-84ca-5301c5e6b51b",
    "outputId": "eaac6b99-4788-45ef-e6d4-654bccc8b68a"
   },
   "outputs": [],
   "source": [
    "# Plot the DecisionTreeClassifier model\n",
    "PlotProbabilities(tree_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88123d15-858f-4aba-9197-bb1f0a8ed39f",
   "metadata": {
    "id": "88123d15-858f-4aba-9197-bb1f0a8ed39f"
   },
   "source": [
    "**What happens if we increase max_depth?**\n",
    "\n",
    "It can be interesting to visualize the decision tree itself. We'll use the GraphViz library to visualize the tree.\n",
    "\n",
    "Note that if you are using Anaconda, GraphViz won't be installed by default. You will need to install graphviz and python-graphviz.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Answer:** In the context of decision trees in machine learning, the max_depth parameter controls the maximum depth of the tree.\n",
    "\n",
    "Let's explore what happens when we increase the value of max_depth:\n",
    "\n",
    "**More Complex Models:** Increasing max_depth will make the tree deeper, allowing it to learn more complex patterns and capture finer details in the data.\n",
    "\n",
    "**Increased Risk of Overfitting:** As max_depth increases, the tree can become increasingly tailored to the training data, capturing noise in addition to underlying patterns. This can result in overfitting, where the model performs well on the training data but poorly on unseen data (i.e., it generalizes poorly to new examples).\n",
    "\n",
    "**Increased Computational Requirements:** A deeper tree means more splits and, consequently, higher computational costs during both the training and prediction phases.\n",
    "\n",
    "**Better Performance on Training Data:** With a higher max_depth, the tree can potentially achieve lower training error because it can fit the training data more closely.\n",
    "\n",
    "**Potentially More Informative:** A deeper tree might reveal more about the underlying structures and patterns in the data, which can be useful from an analytical perspective.\n",
    "\n",
    "**Difficulty in Interpretation:** While decision trees are generally considered to be interpretable models, this interpretability decreases as the tree becomes deeper and more complex. A tree with a very high max_depth can be challenging to visualize and interpret.\n",
    "\n",
    "**To find the optimal max_depth**,\n",
    "\n",
    "one generally uses techniques such as **cross-validation** to assess how well the model generalizes to unseen data and to avoid overfitting.\n",
    "\n",
    "It is often a good practice to start with a **smaller value for max_depth** and gradually increase it while monitoring the model's performance on both the training and validation datasets.\n",
    "\n",
    "Adjusting max_depth is a part of the **hyperparameter tuning process** to build a robust machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292f2ac-916f-4a78-9d26-da80aeb3a621",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "c292f2ac-916f-4a78-9d26-da80aeb3a621",
    "outputId": "8dc25939-fbf2-426c-b119-46568096917c"
   },
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(tree_model,\n",
    "                           feature_names=['EF', 'GLS'],\n",
    "                           class_names=['Healthy', 'Heart Failure'],\n",
    "                           filled=True, rounded=True,\n",
    "                           special_characters=True,\n",
    "                           out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61e3da-ba19-4cff-b3e6-a66f4a72934b",
   "metadata": {
    "id": "cb61e3da-ba19-4cff-b3e6-a66f4a72934b"
   },
   "source": [
    "**The gini parameter is used in the context of decision trees, specifically in the criterion used to decide the best split at each node.**\n",
    "\n",
    "The gini parameter ranges between 0 and 1 and measures **how \"pure\" the data is**, with lower values indicating the data at particular node in the tree is closer to being all one class.\n",
    "\n",
    "**gini = 0.5 means the data is 50% in each class**. Note that the tree includes one leaf node where gini is still 0.5, although it only contains 4 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LFn9j0RMghA2",
   "metadata": {
    "id": "LFn9j0RMghA2"
   },
   "source": [
    "**Gini impurity**\n",
    "\n",
    "Understanding the nuances of Gini impurity and how it impacts the construction and interpretation of decision trees is essential in building robust and interpretable machine learning models. It is a crucial concept in decision tree classification and plays a pivotal role in determining the quality and performance of the decision tree.\n",
    "\n",
    "**verfitting Risks:** Having a leaf node with a high Gini impurity and low sample size might suggest overfitting. In this case, the tree might be capturing noise rather than a genuine underlying pattern, especially if the node is deep in the tree.\n",
    "\n",
    "**Diagnostic Tool:** Analyzing the Gini impurity values at different nodes can provide insights into the decision tree's structure and the underlying data distribution. It can be a valuable diagnostic tool in understanding how well the tree manages to segregate different classes based on the features at hand.\n",
    "\n",
    "Data Inspection: **bold text** Observing a Gini impurity of 0.5 in a leaf node, especially with a small sample size, should prompt a detailed inspection of the data points in that node to understand why the decision tree was unable to segregate them further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb84d2-26d3-4969-a4d6-ab7348700a5f",
   "metadata": {
    "id": "29cb84d2-26d3-4969-a4d6-ab7348700a5f"
   },
   "source": [
    "## Random Forest\n",
    "\n",
    "Finally, let's see if we can improve on the DecisionTree with an ensemble of decision trees using the [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d26ca-fca8-419e-a58e-47fde0122ded",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "f60d26ca-fca8-419e-a58e-47fde0122ded",
    "outputId": "897bb39e-1a48-493c-dec8-a257097f5304"
   },
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "forest_model.fit(X_train, y_train)\n",
    "EvaluateModel(forest_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b11ff1-8fb2-4a8b-8a6c-e48ef7aa071e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "49b11ff1-8fb2-4a8b-8a6c-e48ef7aa071e",
    "outputId": "e0654ff0-de07-4378-99e6-3b794b28a0d2"
   },
   "outputs": [],
   "source": [
    "PlotProbabilities(forest_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac08b9-81b8-41b1-a84f-1e1da5625adf",
   "metadata": {
    "id": "43ac08b9-81b8-41b1-a84f-1e1da5625adf"
   },
   "source": [
    "Notice that the decision boundary is a little closer to the lines obtained with the linear methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683c192b-84a7-48c8-9818-a9b709f83cf8",
   "metadata": {
    "id": "683c192b-84a7-48c8-9818-a9b709f83cf8"
   },
   "source": [
    "## Comparing all the models\n",
    "\n",
    "Finally, we'll compare all the models using the [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) and the ROC-AUC for the test set. We'll use the probabilities where available, otherwise the confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a19f3-19b7-441b-8cba-087d57945d2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "354a19f3-19b7-441b-8cba-087d57945d2b",
    "outputId": "01cb5430-3730-41dd-8873-5a912de74cb3"
   },
   "outputs": [],
   "source": [
    "def PlotROC():\n",
    "    pass\n",
    "\n",
    "label = 'Perceptron'\n",
    "model = p_model\n",
    "fpr, tpr, threshold = roc_curve(y_test, model.decision_function(X_test))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=label+' (area = %0.2f)' % roc_auc, linewidth=1)\n",
    "\n",
    "label = 'Logistic Regression'\n",
    "model = logreg_model\n",
    "fpr, tpr, threshold = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=label+' (area = %0.2f)' % roc_auc, linewidth=1)\n",
    "\n",
    "label = 'Linear SVC'\n",
    "model = linearsvc_model\n",
    "fpr, tpr, threshold = roc_curve(y_test, model.decision_function(X_test))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=label+' (area = %0.2f)' % roc_auc, linewidth=1)\n",
    "\n",
    "label = 'SVC'\n",
    "model = svc_model\n",
    "fpr, tpr, threshold = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=label+' (area = %0.2f)' % roc_auc, linewidth=1)\n",
    "\n",
    "label = 'Kernel SVC'\n",
    "model = kernelsvc_model\n",
    "fpr, tpr, threshold = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=label+' (area = %0.2f)' % roc_auc, linewidth=1)\n",
    "\n",
    "label = 'Decision Tree'\n",
    "model = tree_model\n",
    "fpr, tpr, threshold = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=label+' (area = %0.2f)' % roc_auc, linewidth=1)\n",
    "\n",
    "label = 'Random Forest'\n",
    "model = tree_model\n",
    "fpr, tpr, threshold = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=label+' (area = %0.2f)' % roc_auc, linewidth=1)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"ROC curves\", fontsize=17)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
