{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaralAminpour/ML-BME-Course-UofA-Fall-2023/blob/main/Week-3-Classification-models/4.2%20Binary%20classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTBbXW0vxZud"
      },
      "source": [
        "# Binary classification\n",
        "\n",
        "In this notebook we will practise binary classification in 2D using the example of Logistic regression. We will use the example of prediction of heart failure that you are already familiar with. We will also compare binary classifiers with different pairs of features to see which markers are best predictive of the disease.\n",
        "\n",
        "First we need to import the libraries. Run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbDYHDCrxZuf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMzlczYPxZug"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "Now we will load the dataset. You can see that we have the diagnosis in column **HF**, with labels `0`, `1` and `2`, and three features, **EF**, **GLS** and **QRS**. Run the cells below to load and explore the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r1mkSRAxZug",
        "outputId": "6139eda5-f11e-4d48-fd0d-1d70acde4157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   HF         EF    GLS  QRS\n",
              "0   0  50.922280 -19.57   88\n",
              "1   0  54.601227 -19.00   86\n",
              "2   0  50.000000 -21.00   99\n",
              "3   0  50.819672 -18.74   85\n",
              "4   0  53.191489 -19.78   86"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d74eb8d2-781f-4e66-b6f0-1060ae03cfc0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HF</th>\n",
              "      <th>EF</th>\n",
              "      <th>GLS</th>\n",
              "      <th>QRS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>50.922280</td>\n",
              "      <td>-19.57</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>54.601227</td>\n",
              "      <td>-19.00</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>-21.00</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>50.819672</td>\n",
              "      <td>-18.74</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>53.191489</td>\n",
              "      <td>-19.78</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d74eb8d2-781f-4e66-b6f0-1060ae03cfc0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d74eb8d2-781f-4e66-b6f0-1060ae03cfc0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d74eb8d2-781f-4e66-b6f0-1060ae03cfc0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9732c9fc-c13b-46fd-84a8-be40e0ca316b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9732c9fc-c13b-46fd-84a8-be40e0ca316b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9732c9fc-c13b-46fd-84a8-be40e0ca316b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# This code will download the required data files from GitHub\n",
        "import requests\n",
        "def download_data(source, dest):\n",
        "    base_url = 'https://raw.githubusercontent.com/'\n",
        "    owner = 'SirTurtle'\n",
        "    repo = 'ML-BME-UofA-data'\n",
        "    branch = 'main'\n",
        "    url = '{}/{}/{}/{}/{}'.format(base_url, owner, repo, branch, source)\n",
        "    r = requests.get(url)\n",
        "    f = open(dest, 'wb')\n",
        "    f.write(r.content)\n",
        "    f.close()\n",
        "\n",
        "# Create the temp directory, if it doesn't already exist\n",
        "import os\n",
        "if not os.path.exists('temp'):\n",
        "   os.makedirs('temp')\n",
        "\n",
        "# Download the data\n",
        "download_data('Week-3-Classification-models/data/heart_failure_data_complete.csv', 'temp/heart_failure_data_complete.csv')\n",
        "\n",
        "import pandas as pd\n",
        "# read fine into a dataframe object\n",
        "df = pd.read_csv('temp/heart_failure_data_complete.csv')\n",
        "# print the first few lines\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2lHxt2GxZuh",
        "outputId": "eba8313b-d7e0-4e79-95ab-2d03fb4e0789",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  [0 1 2]\n"
          ]
        }
      ],
      "source": [
        "# print labels\n",
        "print('Labels: ', pd.unique(df['HF']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbY7FBtexZuh"
      },
      "source": [
        "To fit a binary classifier we will only consider 2 classes:\n",
        "* Healthy with label `0`\n",
        "* HF with label either `1` or `2`\n",
        "\n",
        "In the first part of this notebook we will select features **EF** and **GLS**.\n",
        "\n",
        "Run the code below to create the feature matrix `X` and label vector `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPegOGaaxZuh",
        "outputId": "ca1f2f0f-927b-4a44-b950-ddf84d571051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix X dimensions:  (120, 2)\n",
            "Target vector y dimensions:  (120,)\n",
            "Labels:  [0. 1.]\n"
          ]
        }
      ],
      "source": [
        "# convert dataframe to numpy array\n",
        "data = df.to_numpy()\n",
        "\n",
        "# Create feature matrix with EF and GLS\n",
        "X = data[:,[1,2]]\n",
        "\n",
        "# scale the feature matrix\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Create label vector with classes 0 and 1\n",
        "# This slices the first column from data to create the target vector y\n",
        "y = data[:,0]\n",
        "#This replaces all instances of the class label 2 with 1.\n",
        "y[y==2]=1\n",
        "\n",
        "# print properties\n",
        "print('Feature matrix X dimensions: ', X.shape)\n",
        "print('Target vector y dimensions: ', y.shape)\n",
        "print('Labels: ', np.unique(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WVnNeCyxZuh"
      },
      "source": [
        "### Plot the data\n",
        "\n",
        "**Activity 1:** Complete the function `PlotData` and call it to plot the features `X` with different markers based on labels `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm08pBtzxZui"
      },
      "outputs": [],
      "source": [
        "def PlotData(X,y):\n",
        "    # plot class 0\n",
        "    plt.plot(X[y==0,0],X[y==0,1],'bo',alpha=0.75,markeredgecolor='k',label = 'Healthy')\n",
        "    # plot class 1\n",
        "    plt.plot(X[None,None,'rd',alpha=0.75,markeredgecolor='k',label = 'HF')\n",
        "\n",
        "    # annotate the plot\n",
        "    plt.title('Diagnosis of Heart Failure')\n",
        "    plt.xlabel('EF')\n",
        "    plt.ylabel('GLS')\n",
        "    plt.legend()\n",
        "\n",
        "# call the function to plot the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caOFSy2xxZui"
      },
      "source": [
        "### Fit and plot the logistic regression model\n",
        "\n",
        "In the cell below we fit the logistic regression model. Run the cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpEI5h5AxZui"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# create model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA3H36b0xZui"
      },
      "source": [
        "**Activity 2:** Plot the predicted model in 2D. Complete the function `PlotClassification` and run the code below to see the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebkWm1f0xZui"
      },
      "outputs": [],
      "source": [
        "def PlotClassification(model,X,y):\n",
        "\n",
        "    # Create an 1D array of samples for each feature\n",
        "    x1 = np.linspace(-2.5, 2, 1000)\n",
        "    x2 = np.linspace(-3, 3.5, 1000).T # note the transpose\n",
        "    # Creates 2D arrays that hold the coordinates in 2D feature space\n",
        "    x1, x2 = np.meshgrid(x1, x2)\n",
        "    # Flatten x1 and x2 to 1D vector and concatenate into a feature matrix\n",
        "    Feature_space = np.c_[x1.ravel(), x2.ravel()]\n",
        "\n",
        "    # Predict labels for the whole feature space\n",
        "    y_pred = None\n",
        "    # Resahpe to 2D\n",
        "    y_pred = y_pred.reshape(x1.shape)\n",
        "    # Plot using contourf\n",
        "    plt.contourf(x1, x2, y_pred, cmap = 'summer')\n",
        "\n",
        "    # Plot data\n",
        "    PlotData(X,y)\n",
        "\n",
        "# Plot classification\n",
        "PlotClassification(model,X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caUOxu76xZuj"
      },
      "source": [
        "**Activity 3:** Complete function `PlotProbabilities` to plot the probability for the class 1. Change label form `1` to `0` to see the probability for class 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdVGU6PmxZuj"
      },
      "outputs": [],
      "source": [
        "def PlotProbabilities(model,X,y,label=1):\n",
        "\n",
        "    # Create an 1D array of samples for each feature\n",
        "    x1 = np.linspace(-2.5, 2, 1000)\n",
        "    x2 = np.linspace(-3, 3.5, 1000).T # note the transpose\n",
        "    # Creates 2D arrays that hold the coordinates in 2D feature space\n",
        "    x1, x2 = np.meshgrid(x1, x2)\n",
        "    # Flatten x1 and x2 to 1D vector and concatenate into a feature matrix\n",
        "    Feature_space = np.c_[x1.ravel(), x2.ravel()]\n",
        "\n",
        "    # Predict labels for the whole feature space\n",
        "    proba = None\n",
        "    # Select the class\n",
        "    p = proba[:,label]\n",
        "    # Resahpe to 2D\n",
        "    p = p.reshape(x1.shape)\n",
        "    # Plot using contourf\n",
        "    plt.contourf(x1, x2, p, cmap = 'summer')\n",
        "\n",
        "    # Plot data\n",
        "    PlotData(X,y)\n",
        "\n",
        "# Plot probabilities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmeDKguoxZuj"
      },
      "source": [
        "**Activity 4:** Logistic regression model is scikit-learn includes a Ridge penalty, that is controlled by hyperparameter `C`. In the cell bellow, try different values of alpha to see the effect of Ridge penalty on the predicted probabilities of class 1. You can try for example `1000`, `1`, `0.001`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge Penalty\n",
        "\n",
        "Ridge penalty is a form of **regularization** used in machine learning **to prevent overfitting**.\n",
        "\n",
        "Overfitting happens when a model **learns** the training data **too well**, capturing its **noise and outliers**, which reduces the model's ability to **generalize to new, unseen data**.\n",
        "\n",
        "To mitigate this, the Ridge **penalty is added to the standard loss function of logistic regression**. This acts as a **constraint** that **discourages the model** from fitting the training data too closely, which helps the model **generalize better** to new, unseen data.\n",
        "\n",
        "In logistic regression with Ridge regularization, the standard log loss function **is augmented with a penalty term**:\n",
        "\n",
        "$$\n",
        "\\text{Loss function with Ridge penalty} = \\text{Log Loss} + \\frac{1}{2C} \\sum_{i=1}^{n} w_i^2\n",
        "$$\n",
        "\n",
        "Here, $w_i$ are the model weights and $C$ is the hyperparameter that controls the strength of the Ridge penalty.\n",
        "\n",
        "- **$C$ is actually the inverse of the regularization strength ($\\alpha$)** commonly used in Ridge regression.\n",
        "\n",
        "- Therefore, **smaller values of $C$** lead to **stronger regularization** and shrink the weights **$w_i$ towards zero**.\n",
        "\n",
        "- **Larger values of $C$**, on the other hand, yield **weaker regularization**, making the loss function closer to the original log loss.\n",
        "\n",
        "The Ridge penalty is especially useful in scenarios where\n",
        "\n",
        "- you have a **high-dimensional feature space**,\n",
        "\n",
        "- **relatively less data**, or when\n",
        "\n",
        "- **many features are correlated**.\n",
        "\n",
        "By tweaking the $C$ parameter, you can control how much the **model focuses on fitting the training data versus generalizing to new data**.\n",
        "\n",
        "Smaller values of $C$ make the model more robust but less sensitive to the training data, while larger values of $C$ allow the model to fit the training data more closely, at the risk of overfitting.\n",
        "\n",
        "Therefore, **the $C$ parameter offers a way to balance the trade-off between overfitting and underfitting**, enabling the construction of a model that generalizes well to new, unseen data."
      ],
      "metadata": {
        "id": "qU6DgziNH05u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiO8VtenxZuj"
      },
      "outputs": [],
      "source": [
        "# set alpha\n",
        "model = LogisticRegression(C = 1000)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X,y)\n",
        "\n",
        "# Plot probabilities\n",
        "PlotProbabilities(model,X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBvIOVoNxZuj"
      },
      "source": [
        "### Evaluate performance of the classifier\n",
        "\n",
        "The simplest way to evaluate performance of the classifier is using **accuracy score**. This score is a good evaluation measure for **balanced** datasets, where the number of samples of each class is similar.\n",
        "\n",
        "**Actvity 5:** Check whether our dataset is balanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOge9edWxZuj"
      },
      "outputs": [],
      "source": [
        "print('Number of samples of class 0: ', y[y==0].shape[0])\n",
        "print('Number of samples of class 1: ', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssllBMEmxZuk"
      },
      "source": [
        "**Activity 6:** Calculate the cross-validated accuracy for the default model. To do that complete the the function `Accuracy_CV`.\n",
        "\n",
        "*Hint:* Use function `cross_val_score`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzERUuHrxZuk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# cross-validated accuracy\n",
        "def Accuracy_CV(model,X,y):\n",
        "    scores = None\n",
        "    print('Accuracy CV: ',round(scores.mean(),2))\n",
        "\n",
        "# select default Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X,y)\n",
        "\n",
        "# Evaluate accuracy\n",
        "Accuracy_CV(model,X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgNFs-hUxZuk"
      },
      "source": [
        "For the balanced datasets, the accuracy is a good measure. For balanced binary dataset, accuracy higher than 0.5 means that the classifier managed to learn some information about the data (0.5 corresponds to a random assignment of the labels). We can check this for our dataset by calculating also **sensitivity** and **specificity**, and check that they are both high.\n",
        "\n",
        "**Activity 7:** Calculate sensitivity and specificity for the fitted model.\n",
        "\n",
        "*Hint:* Use function `recall_score`. Remember from the lecture, that recall for positive label set to 1 is sensitivity, while recall for positive label set to 0 is specificity. Positive label is set using argument `pos_label`. Average recall can be calculated by setting `average='macro'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggtvyMJAxZuk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Predict labels using cross-validation\n",
        "y_pred = cross_val_predict(model,X,y)\n",
        "\n",
        "# Sensitivity\n",
        "sensitivity = recall_score(y,y_pred,pos_label = 1)\n",
        "print('Sensitivity: ',round(sensitivity,2))\n",
        "\n",
        "# Specificity\n",
        "specificity = None\n",
        "print('Specificity: ',round(specificity,2))\n",
        "\n",
        "# Average recall\n",
        "mean_recall = recall_score(y,y_pred,average=None)\n",
        "print('Mean Recall: ',round(mean_recall,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MyvHh_IxZuk"
      },
      "source": [
        "<img src=\"https://github.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/blob/main/Week-3-Classification-models/images/QRS.png?raw=1\" width = \"200\" style=\"float: right;\">\n",
        "## Exercise 2: Compare classifiers\n",
        "\n",
        "Global longitudinal strain is difficult to estimate correctly due to manual measurements that need to be performed, resulting in poor reproducibility. Researchers believe, that GLS could be replaces by duration of QRS interval extracted from ECG, that is much easier to measure.\n",
        "\n",
        "Your task is to compare the classifier that predicts heart failure from EF and GLS with the classifier that predict HF from EF and QRS.\n",
        "\n",
        "### Create dataset with EF and QRS\n",
        "Run the code bellow to create a feature matrix `X2` that contains EF and QRS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6abEsScLxZuk"
      },
      "outputs": [],
      "source": [
        "# Create a feature matrix with EF and QRS\n",
        "X2 = data[:,[1,3]]\n",
        "X2 = scaler.fit_transform(X2)\n",
        "\n",
        "# Plot the new dataset\n",
        "PlotData(X2,y)\n",
        "plt.ylabel('QRS')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8KM4xl6xZuk"
      },
      "source": [
        "### Task 1: Fit and plot the model\n",
        "\n",
        "Fit the default Logistic regression model to the EF QRS dataset and plot the classification results using function `PlotClassification`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqNWiBFkxZuk"
      },
      "outputs": [],
      "source": [
        "# select the model\n",
        "model2 = None\n",
        "\n",
        "# fit the model\n",
        "\n",
        "\n",
        "# plot classification results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ogwNxffxZul"
      },
      "source": [
        "### Task 2: Performance\n",
        "\n",
        "Complete the function `EvaluatePerformance` to calculate **cross-validated**\n",
        "* accuracy\n",
        "* sensitivity\n",
        "* specificity\n",
        "* average recall\n",
        "\n",
        "Run the function to print out the performance measures and compare to the EF GLS dataset. Which of the dataset is better for prediction of heart failure?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFTKcYfWxZul"
      },
      "outputs": [],
      "source": [
        "def EvaluatePerformance(model,X,y):\n",
        "\n",
        "    # accuracy\n",
        "    scores = None\n",
        "    print('Accuracy: ', round(scores.mean(),2))\n",
        "\n",
        "    # Predict labels using cross-validation\n",
        "    y_pred = None\n",
        "\n",
        "    # Sensitivity\n",
        "    sensitivity = None\n",
        "    print('Sensitivity: ',round(sensitivity,2))\n",
        "\n",
        "    # Specificity\n",
        "    specificity = None\n",
        "    print('Specificity: ',round(specificity,2))\n",
        "\n",
        "    # Average recall\n",
        "    mean_recall = None\n",
        "    print('Mean Recall: ',round(mean_recall,2))\n",
        "\n",
        "\n",
        "# Calculate performance for EF QRS dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC1n1BFExZul"
      },
      "source": [
        "### Task 3: Tuning the Ridge penalty (optional)\n",
        "\n",
        "Find out whether the performance of the EF QRS model can be further improved by tuning the hyperparameter `C` that controls the strength of Ridge regularisation.\n",
        "* Use function `GridSearchCV` to tune `C`\n",
        "* Print out the best parameter `C` and best score\n",
        "* Plot the classification boundary and the probabilites for class 1\n",
        "* Calculate performance all measures for the new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0ChaDrKxZul"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# parameter grid\n",
        "param = {'C':np.logspace(-3,3,7)}\n",
        "\n",
        "# grid search\n",
        "g = None\n",
        "g.fit(None,None)\n",
        "\n",
        "# best model\n",
        "best_model = None\n",
        "\n",
        "# print best accuracy score\n",
        "print('Accuracy: ', round(g.best_score_,2))\n",
        "\n",
        "# print best C\n",
        "print('C: ', best_model.C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk69rMG_xZul"
      },
      "outputs": [],
      "source": [
        "# plot the decision boundary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTnRx7mzxZum"
      },
      "outputs": [],
      "source": [
        "# plot the probability for class 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAl4ioKfxZum"
      },
      "outputs": [],
      "source": [
        "# calculate performance measures\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_05W51jxZum"
      },
      "source": [
        "Is the performance of the tuned Logistic Regression better than default?\n",
        "\n",
        "**Answer:**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}