{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas package is an extremely powerful library for manipulating tabular data. Similar in some ways to Excel, pandas provides functionality for reading data from spreadsheets (in a range of formats including Excel, csv and pickle files) and presenting them as a Dataframe object. Through this, it becomes possible to search, filter and manipulate the data entries. In this notebook, we will go through some of the basic functionality of Pandas, sufficient for reading in data, selecting columns and filtering by different search categories. \n",
    "\n",
    "We start by importing Pandas (and the other modules we'll need):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is capable of working with data from a range of statistical software packages (Excel, SQL, Stata, SAS). In this course, we will focus simply on reading from .csv and pickle files e.g. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "\n",
    "# Download data from GitHub\n",
    "def download_data(source, dest):\n",
    "    base_url = 'https://raw.githubusercontent.com/'\n",
    "    owner = 'SirTurtle'\n",
    "    repo = 'ML-BME-UofA-data'\n",
    "    branch = 'main'\n",
    "    url = '{}/{}/{}/{}/{}'.format(base_url, owner, repo, branch, source)\n",
    "    r = requests.get(url)\n",
    "    f = open(dest, 'wb')\n",
    "    f.write(r.content)\n",
    "    f.close()\n",
    "\n",
    "if not os.path.exists('temp'):\n",
    "   os.makedirs('temp')\n",
    "\n",
    "download_data('Week-1-Python-programming/data/40subjdata.pkl', 'temp/40subjdata.pkl')\n",
    "download_data('Week-1-Python-programming/data/dHCP_volume_data.csv', 'temp/dHCP_volume_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = pd.read_pickle('temp/40subjdata.pkl') # reading from a pickle file\n",
    "dHCP_volume_data = pd.read_csv('temp/dHCP_volume_data.csv', header=None) # reading from a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open 'dHCP_volume_data.csv' using Excel. You will note it has no column names. Thus in order to load all data correctly (and avoid the first row of data being read in as column headers) it is necessary to supplement the call to ```read_csv``` with an additional argument ```header=None```. Other potentially important read arguments include ```sep``` or ```delimeter``` which define the delimeter used to separate the columns in the saved spreadsheet. For more information see (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). \n",
    "\n",
    "To avoid this confusion over csv formatting one option is to save and then reload dataframes as pickle files (see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_pickle.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing and Inspecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides several functions for viewing subsections of the DataFrame and estimating summary statistics across columns. For example, it is possible to read the first (or last) few rows of the data using the ```head``` and ```tail``` functions respectively. The parameter is the number of data lines to print. (We are using display instead of print to show a more nicely formatted version of the data in a notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(student_data.head(3))\n",
    "display(student_data.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1:__ Print first 10 and last 7 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(student_data.head(10))\n",
    "display(student_data.tail(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, several functions are provided to summarise statistics across columns:\n",
    "\n",
    "-  `df.mean()` Returns the mean of all columns\n",
    "-  `df.max()`  Returns the highest value in each column\n",
    "-  `df.min()` Returns the lowest value in each column\n",
    "-  `df.median()` Returns the median of each column\n",
    "-  `df.std()` Returns the standard deviation of each column\n",
    "-  `df.corr()` Returns the correlation between columns in a data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataframes from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes can be created from dictionaries, lists or NumPy arrays. Below is an example of creating a new dataframe from a 4-column array, within given column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an array of random numbers with four columns\n",
    "random_array = np.random.randint(0, 100, size=(10,4))\n",
    "\n",
    "# Creating a new data frame object from the random array and providing column  labels\n",
    "df = pd.DataFrame(random_array, index=['a','b','c','d','e','f','g','h','i','j'], columns=['A','B','C','D'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2__: Create an array of 100 rows and 2 columns and populate it with normally distributed random values (_Hint_: `randn`). Create a data frame object from this array (do not provide index labels this time, only column labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 2\n",
    "gaussian_array = np.random.randn(100, 2)\n",
    "df2 = pd.DataFrame(gaussian_array, columns=['A', 'B'])\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New columns can straightforwardly be added in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['E'] = df['A'] + df['B']\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows you to create new columns of data from existing columns, as you could with a formula in Excel.\n",
    "\n",
    "__Task 3__: Create a new column called 'F' containing: $\\text{mean}(A) + 5B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns and rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to select a single column from a DataFrame using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['A'])\n",
    "print('Column object type:', type(df['A']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see a DataFrame column is represented by a separated datatype: a Series. Essentially a Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.). The axis labels are collectively called index. Rows can be selected as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select a range of columns and rows (using the column names and row indices) use the ```.loc``` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a range or rows and columns by name\n",
    "display(df.loc['a':'d', 'A':'C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be used to obtain a single scalar value, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a scalar value\n",
    "x = df.loc['b','A']\n",
    "print('Selecting a single value: {}, given type: {}'.format(x, type(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to slice by column and row number use ```iloc```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a range or rows and columns by number\n",
    "df.iloc[0:4,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 4:__ From `student_data` select\n",
    "1. Rows 2 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Column 'height'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Rows 0 and 1 and columns 0 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Rows 0 to 2 and columns 'distance' to 'height'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be filtered using conditional statements such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['A'] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This selects all rows for which the values in the column 'A' are greater than 50. To further reduce this data to the values in column 'C':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['C'][df['A'] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 5:__ Select from `student_data` the column 'height' for the female students only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occasionally it can be useful to iterate through all the rows in the DataFrame (for example if it stores paths to files that need to be processed). This can be achieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(index, row['A'], row['E'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, ```row``` is a Series containing the content of each indexed row. The values from different columns in this row can therefore be indexed as `row['A'], row['B']` ... etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you will want to merge two DataFrames that share information. For example, creating a new DataFrame that shares Columns 'A' and 'B' with ```df```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of random numbers with four columns\n",
    "random_array = np.random.randint(0,100,size=(10,3))\n",
    "\n",
    "# Create a new data frame object from the random array and providing column  labels\n",
    "df_new = pd.DataFrame(random_array, index=['a','b','c','d','e','f','g' ,'h','i','j'], columns=['F','G','H'])\n",
    "df_new['A'] = df['A']\n",
    "df_new['B'] = df['B']\n",
    "display(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the two DataFrames can be merged on these columns using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_new, on=['A','B'])\n",
    "display(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as seen previously for the Matplotlib tutorial, it is possible to directly plot the columns of the DataFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(student_data['height'], student_data['distance'])\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Distance Travelled')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 6:__ Plot a histogram of heights of the female students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations & Extended Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Pandas in your research you should consider citing\n",
    "\n",
    "Wes McKinney. Data Structures for Statistical Computing in Python, Proceedings of the 9th Python in Science Conference, 51-56 (2010) (publisher link)\n",
    "\n",
    "For more comprehensive tutorials on using Pandas see:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
